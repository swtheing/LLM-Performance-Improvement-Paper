# LLM-Performance-Improvement-Paper
## Overview
![The paradigm of improving the performance of LLM](https://github.com/swtheing/LLM-Performance-Improvement-Paper/blob/main/The%20paradigm%20of%20improving%20the%20performance%20of%20LLM.png)

## Paper List
### [1] Scale laws
### [2] Diversity & Quality
LIMA : Less Is More for Alignment

Textbooks are all you need
### [3] Filter Model
Textbooks are all you need

GPT3:Language Models are Few-Shot Learners
### [4][5] Teacher Model & Zero shot labelling
Textbooks are all you need

GPT Self-Supervision for a Better Data Annotator
### [6] Reward Model
Lets Verify Step by Step
### [7] RLHF or DPO
Training language models to follow instructions with human feedback

Direct Preference Optimization: Your Language Model is Secretly a Reward Model
### [8] Instruct Understanding & Prompt-Answer Matching
Training language models to follow instructions with human feedback

LIMA : Less Is More for Alignment

The Flan Collection: Designing Data and Methods for Effective Instruction Tuning
### [9] Self Instruct from GPT
Aligning Language Models with Self-Generated Instructions

SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions

Wizardlm: Empowering large language models to follow complex instructions

WizardCoder: Empowering Code Large Language Models with Evol-Instruct

Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation

   
